## Самигуллин Равиль гр6133

Для реализации на c++ я использовал инструкцию на [geekforgeeks](https://www.geeksforgeeks.org/how-to-run-cuda-c-c-on-jupyter-notebook-in-google-colaboratory/).

Каждый поток использует функцию 'atomicAdd' для атомарного сложения своего элемента вектора к общей переменной 'sum'. Это гарантирует, что не будет возникать гонок данных '(race conditions)' при одновременном доступе нескольких потоков к одной и той же переменной 'sum'.

Значение blocksPerGrid определяется следующим образом:

'(size + threadsPerBlock - 1) / threadsPerBlock' - это операция округления вверх количества блоков.

'size' - общее количество элементов в массиве данных, которые нужно обработать.

Описание работы функции 'atomicAdd':
1. Значение в памяти по адресу 'sum' считывается.
2. К полученному значению прибавляется 'vec[tid]'.
3. Новое значение полученной суммы записывается обратно в память по адресу 'sum'.
4. Возвращается предыдущее значение переменной перед сложением '(sum + vec[tid])'.

Таблица результатов умножения время миллисекунды.

| матрица      | 10x10x10 |1000x1000x1000|100x10x1000 |1000x1000x10000|
| ---          |     ---  |  ---         |        --- | ---           |
| Правильность | CORRECT  |	CORRECT      |	CORRECT   |	CORRECT       |
| CPU Time     | 0.004 m  |	3936.7 m     |	3.029 m   |	62781.3 m     |
| GPU Time     | 0.02048 m|	6.99731 m    |	0.033184 m|	70.0657 m     |

m – milliseconds

Выводы: Меньшее количество вычислений происходит быстрее на CPU, но при увеличении количества умножений они происходят быстрее на GPU.

Параллельное выполнение операции перемножения матриц на GPU с использованием CUDA позволяет использовать мощности параллельной обработки GPU для ускорения вычислений в сравнении с последовательным выполнением на CPU.
