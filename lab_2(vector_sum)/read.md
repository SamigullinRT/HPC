## Самигуллин Равиль гр6133

Для реализации на c++ я использовал инструкцию на [geekforgeeks](https://www.geeksforgeeks.org/how-to-run-cuda-c-c-on-jupyter-notebook-in-google-colaboratory/).

Каждый поток использует функцию `atomicAdd` для атомарного сложения своего элемента вектора к общей переменной `sum`. Это гарантирует, что не будет возникать гонок данных `(race conditions)` при одновременном доступе нескольких потоков к одной и той же переменной `sum`.

Значение blocksPerGrid определяется следующим образом:

`(size + threadsPerBlock - 1) / threadsPerBlock` - это операция округления вверх количества блоков.

`size` - общее количество элементов в массиве данных, которые нужно обработать.

Описание работы функции 'atomicAdd':
1. Значение в памяти по адресу `sum` считывается.
2. К полученному значению прибавляется `vec[tid]`.
3. Новое значение полученной суммы записывается обратно в память по адресу `sum`.
4. Возвращается предыдущее значение переменной перед сложением `(sum + vec[tid])`.

Ускорение посчитал как отношение скорости CPU к GPU.

Таблица результатов умножения время миллисекунды.

| матрица      |   10^5       |    10^6       |     10^7    |      10^    |           10^9      |    10^10       |
| ---          |     ---      |  ---          |         --- | ---         |         ---         |   ---          |
| CPU Time     | 0,00823493 s |	0,0517334 s   |	0,496744 s  |	6,08973 s   |      11,5331 s      |    11,5292 s   |
| GPU Time     | 0,000120619 s|	0,000566167 s |	0,00489625 s|	0,0484632 s |     0,000080692 s   |    0,00009522 s|
|ускорение     |68,2          |     91,37     |  101,453    | 125,65      |   142927,4          | 121079,6       |
s – seconds

Выводы: Меньшее количество вычислений происходит быстрее на CPU, но при увеличении количества умножений они происходят быстрее на GPU, так же у меня ускорениесильно увеличивается при переходе к 10 значному вектору, причем в данном случае, аремя вычисления меньше даже чем при прошлом вычислении, я думал при увеличении нагрузки оно увеличится так как количество блоков не бесконечно и обработка пойдет по второму кругу, я не знаю с чем связать полученное время вычисления, разве что с ошибкой таймера возникающей при данной операции.

Параллельное выполнение операции сложения элементов вектора на GPU с использованием CUDA позволяет использовать мощности параллельной обработки GPU для ускорения вычислений в сравнении с последовательным выполнением на CPU.
